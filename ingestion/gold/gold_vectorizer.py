# ============================================================
# ðŸŸ¡ ingestion/gold/gold_vectorizer.py â€” versÃ£o local (Ollama)
# ============================================================
import os
from pathlib import Path
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import FAISS

class GoldVectorizer:
    def __init__(self):
        self.index_path = Path("gold/knowledge_index")
        self.index_path.parent.mkdir(parents=True, exist_ok=True)

        # Define o modo padrÃ£o
        self.embedding_mode = os.getenv("EMBED_MODE", "ollama")  

        # Nome do modelo local (pode mudar conforme o que vocÃª baixou)
        self.ollama_model = os.getenv("OLLAMA_EMBED_MODEL", "embeddinggemma")

    def build_index(self, chunks):
        print(f"ðŸ§© Usando modo de embeddings: {self.embedding_mode}")


            # ðŸ”¹ Usa embeddings locais via Ollama
        embeddings = OllamaEmbeddings(model=self.ollama_model)

        # Cria e salva o Ã­ndice FAISS
        index = FAISS.from_documents(chunks, embeddings)
        index.save_local(str(self.index_path))
        print(f"ðŸŸ¡ Gold: Ã­ndice vetorial salvo em {self.index_path}")
        return index
