### ğŸŒŒ CoreLayer GPT Memory System

A **symbiotic system** for ingestion, memory, and contextual reasoning built on the **Medallion Architecture** pattern â€” designed to create a **living, self-evolving AI**, with independent layers for ingestion, vectorization, memory, and reasoning.

---

## ğŸ§  Overview

The **CoreLayer GPT Memory System** organizes AI cognition into **symbolic processing and memory layers**.  
It follows the **Bronze â†’ Silver â†’ Gold â†’ Catalog â†’ Prompt â†’ Memory â†’ Core** model, forming a self-expanding pipeline that reads, understands, stores, and reasons over real data in real time.

---

## ğŸ§© General Architecture

ğŸŸ¤ BRONZE â€” Raw data ingestion  
âšª SILVER â€” Semantic processing and cleaning  
ğŸŸ¡ GOLD â€” Vectorization and knowledge indexing  
ğŸ”µ CATALOG â€” Universal index and cognitive governance  
ğŸŸ¢ PROMPT â€” Intent control and versioning  
ğŸŸ£ MEMORY â€” Symbiotic short- and long-term memory  
âš« CORE â€” Contextual GPT reasoning (RAG)  
ğŸ”´ OBSERVABILITY â€” Metrics, logs, and cognitive audit  

---

## ğŸ“‚ Folder Structure

```bash
corelayer/
â”‚
â”œâ”€â”€ main.py                        # Symbiotic orchestration core
â”‚
â”œâ”€â”€ core/
â”‚   â””â”€â”€ rag_pipeline.py             # Reasoning and retrieval pipeline (RAG)
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ bronze/bronze_loader.py     # Parallel ingestion and data loading
â”‚   â”œâ”€â”€ silver/silver_processor.py  # Text splitting and semantic cleaning
â”‚   â”œâ”€â”€ gold/gold_vectorizer.py     # Vectorization (embeddings + FAISS)
â”‚   â”œâ”€â”€ catalog/catalog_manager.py  # Universal index (datasets, prompts, vectors)
â”‚   â”œâ”€â”€ prompt/prompt_layer.py      # Prompt versioning and templates
â”‚   â”œâ”€â”€ memory/memory_manager.py    # Symbiotic short- and long-term memory
â”‚   â””â”€â”€ observability/              # (in progress) monitoring and metrics
â”‚
â””â”€â”€ README.md                       # This document
```
---

## âš™ï¸ Requirements

### ğŸ”§ Main Dependencies
- Python â‰¥ 3.10  
- LangChain â‰¥ 0.2  
- Ollama (for local model inference)  
- FAISS  
- dotenv (optional)  

Recommended installation:
```bash
pip install langchain langchain-openai langchain-community faiss-cpu
```

Create a directory with your initial ingestion files:
```bash
mkdir bronze_data
cp /path/to/your/files/*.pdf bronze_data/
```

---

## ğŸš€ Run

Start the system:
```bash
python3 main.py
```

The full symbiotic pipeline will execute:

- Bronze â†’ load and read documents  
- Silver â†’ process and chunk text  
- Gold â†’ embed and index vectors  
- Catalog â†’ register dataset and embeddings  
- Core â†’ interactive reasoning with memory  

---

## ğŸ§© Core Components

### ğŸŸ¤ BronzeLoader
Loads all PDF and TXT files in parallel and converts them into LangChain documents.

### âšª SilverProcessor
Cleans and splits the content into semantically meaningful text chunks.

### ğŸŸ¡ GoldVectorizer
Generates embeddings (via Ollama or Azure) and builds a persistent FAISS vector index.

### ğŸ”µ CatalogManager
Maintains a complete registry of datasets, embeddings, prompts, and memory records.

### ğŸŸ¢ PromptLayer
Manages and versions prompts, allowing domain-specific intent evolution.

### ğŸŸ£ MemoryManager
Stores recent interactions (short-term) and automatically generates long-term summaries.

### âš« RagPipeline
Combines memory, vector retrieval, and GPT/Ollama reasoning into contextualized, evolving responses.

---

## ğŸ§‘â€ğŸ’» Author

**Yuri Freitas**  
Developer and researcher in **symbiotic AI architectures**, cognitive memory systems, and self-evolving reasoning pipelines.
